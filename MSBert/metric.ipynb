{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from const import gnps, mona\n",
    "from type import TokenizerConfig\n",
    "from data import Tokenizer\n",
    "from utils import load_model, search, search_with_spectra, embedding, most_similar, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(device)\n",
    "\n",
    "batch_size = None\n",
    "k_metric = [5, 1, 10]\n",
    "loader_batch_size = 512\n",
    "show_progress_bar = False\n",
    "\n",
    "replica_suffix = \"-replication-{}\"\n",
    "\n",
    "tokenizer_config = TokenizerConfig(\n",
    "    max_len=100,\n",
    "    n_decimals=2,\n",
    "    show_progress_bar=show_progress_bar\n",
    ")\n",
    "tokenizer = Tokenizer(**tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_paths = {\n",
    "    \"gnps\":{\n",
    "        \"orbitrap\": {\n",
    "            \"train\": (gnps.ORBITRAP_TRAIN_QUERY, gnps.ORBITRAP_TEST_REF),\n",
    "            \"test\": (gnps.ORBITRAP_TEST_QUERY, gnps.ORBITRAP_TEST_REF)\n",
    "        },\n",
    "        \"qtof\": {\n",
    "            \"test\": (gnps.QTOF_TEST_QUERY, gnps.QTOF_TEST_REF)\n",
    "        },\n",
    "        \"other\": {\n",
    "            \"test\": (gnps.OTHER_TEST_QUERY, gnps.OTHER_TEST_REF)\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "gnps_train_ref = np.load(gnps.ORBITRAP_TRAIN_REF, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:58<35:47, 238.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764268  0.883959  0.906437\n",
      "gnps-orbitrap-test   0.780546  0.892645  0.912811\n",
      "gnps-qtof-test       0.497074  0.663032  0.704122\n",
      "gnps-other-test      0.748876  0.886064  0.907611\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [07:55<31:43, 237.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764122  0.884250  0.906583\n",
      "gnps-orbitrap-test   0.786477  0.895611  0.918149\n",
      "gnps-qtof-test       0.494814  0.665293  0.705452\n",
      "gnps-other-test      0.751046  0.882499  0.908386\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [11:49<27:29, 235.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764852  0.883959  0.906437\n",
      "gnps-orbitrap-test   0.762752  0.892052  0.908660\n",
      "gnps-qtof-test       0.488165  0.660771  0.698537\n",
      "gnps-other-test      0.739730  0.880794  0.903736\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [15:49<23:44, 237.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764560  0.883959  0.906583\n",
      "gnps-orbitrap-test   0.775801  0.889680  0.912811\n",
      "gnps-qtof-test       0.498936  0.666755  0.706516\n",
      "gnps-other-test      0.758177  0.891180  0.913037\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [19:17<18:54, 226.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764268  0.884250  0.906729\n",
      "gnps-orbitrap-test   0.777580  0.891459  0.912811\n",
      "gnps-qtof-test       0.491356  0.661436  0.703856\n",
      "gnps-other-test      0.747016  0.885754  0.906836\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [22:47<14:45, 221.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764560  0.883375  0.906729\n",
      "gnps-orbitrap-test   0.782325  0.900356  0.918149\n",
      "gnps-qtof-test       0.493484  0.664495  0.702261\n",
      "gnps-other-test      0.747791  0.882499  0.903116\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [26:19<10:54, 218.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764852  0.883959  0.906437\n",
      "gnps-orbitrap-test   0.778173  0.887900  0.914591\n",
      "gnps-qtof-test       0.492553  0.664229  0.699734\n",
      "gnps-other-test      0.749186  0.884824  0.910867\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [29:48<07:10, 215.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764414  0.884834  0.906875\n",
      "gnps-orbitrap-test   0.780546  0.891459  0.910439\n",
      "gnps-qtof-test       0.494548  0.665160  0.703059\n",
      "gnps-other-test      0.748721  0.883894  0.909626\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [33:19<03:33, 213.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.764560  0.884105  0.906875\n",
      "gnps-orbitrap-test   0.771056  0.887307  0.909253\n",
      "gnps-qtof-test       0.496809  0.660771  0.703989\n",
      "gnps-other-test      0.747171  0.881104  0.907301\n",
      "---------------------------------------- gnps-orbitrap-train ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-orbitrap-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-qtof-test ----------------------------------------\n",
      "tokenize the query and reference data success\n",
      "---------------------------------------- gnps-other-test ----------------------------------------\n",
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [36:47<00:00, 220.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         top1      top5     top10\n",
      "gnps-orbitrap-train  0.765582  0.884542  0.906437\n",
      "gnps-orbitrap-test   0.785884  0.890273  0.912811\n",
      "gnps-qtof-test       0.494016  0.660904  0.702261\n",
      "gnps-other-test      0.744071  0.884049  0.907611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "replica_df_seq = []\n",
    "for i in tqdm(range(10)):\n",
    "    df_seq = []\n",
    "    for db, db_metadata in spectra_paths.items():\n",
    "        for desc, path_metadata in db_metadata.items():\n",
    "            for info, paths in path_metadata.items():\n",
    "                print(\"-\" * 40, f\"{db}-{desc}-{info}\", \"-\" * 40)\n",
    "                query_path, ref_path = paths\n",
    "                query_path = query_path.with_stem(query_path.stem + replica_suffix.format(i + 1))\n",
    "                ref_path = ref_path.with_stem(ref_path.stem + replica_suffix.format(i + 1))\n",
    "                if db == \"gnps\" and desc == \"orbitrap\":\n",
    "                    if info == \"train\":\n",
    "                        query_path = gnps.ORBITRAP_TRAIN_QUERY\n",
    "                    \n",
    "                    ref_spectra = np.load(ref_path, allow_pickle=True)\n",
    "                    query_spectra = np.load(query_path, allow_pickle=True)\n",
    "                    ref_spectra = np.hstack((gnps_train_ref, ref_spectra))\n",
    "                    df = search_with_spectra(\n",
    "                        f\"{db}-{desc}-{info}\", tokenizer,\n",
    "                        model, device,\n",
    "                        query_spectra, ref_spectra,\n",
    "                        k_metric,\n",
    "                        loader_batch_size, batch_size,\n",
    "                        show_progress_bar\n",
    "                    )\n",
    "                else:\n",
    "                    df = search(\n",
    "                        f\"{db}-{desc}-{info}\", tokenizer,\n",
    "                        model, device,\n",
    "                        query_path, ref_path,\n",
    "                        k_metric,\n",
    "                        loader_batch_size, batch_size,\n",
    "                        show_progress_bar\n",
    "                    )\n",
    "                df_seq.append(df)\n",
    "    df = pd.concat(df_seq, axis=0)\n",
    "    print(df)\n",
    "    replica_df_seq.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "indices = replica_df_seq[0].index\n",
    "columns = replica_df_seq[0].columns\n",
    "for item in replica_df_seq:\n",
    "    data.append([item.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[76.46, 88.41, 90.66],\n",
       "        [77.81, 89.19, 91.3 ],\n",
       "        [49.42, 66.33, 70.3 ],\n",
       "        [74.82, 88.43, 90.78]]),\n",
       " array([[0.04, 0.04, 0.02],\n",
       "        [0.67, 0.36, 0.31],\n",
       "        [0.29, 0.21, 0.23],\n",
       "        [0.45, 0.29, 0.28]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "np.mean(data, axis=0) * 100, np.std(data, axis=0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 2)\n",
    "mean_df = pd.DataFrame(np.mean(data, axis=0) * 100, index=indices, columns=columns)\n",
    "std_df = pd.DataFrame(np.std(data, axis=0) * 100, index=indices, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df.to_csv(\"./mean.tsv\", sep='\\t')\n",
    "std_df.to_csv(\"./std.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate hit and recall count: 100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top5</th>\n",
       "      <th>top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MTBLS1572</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               top1  top5  top10\n",
       "MTBLS1572  0.904762   1.0    1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(device)\n",
    "\n",
    "batch_size = None\n",
    "k_metric = [5, 1, 10]\n",
    "loader_batch_size = 512\n",
    "show_progress_bar = False\n",
    "\n",
    "replica_suffix = \"-replication-{}\"\n",
    "\n",
    "tokenizer_config = TokenizerConfig(\n",
    "    max_len=100,\n",
    "    n_decimals=2,\n",
    "    show_progress_bar=show_progress_bar\n",
    ")\n",
    "tokenizer = Tokenizer(**tokenizer_config)\n",
    "\n",
    "query_spectra = np.load(\"/data1/xp/data/MSBert/MTBLS1572/query.npy\", allow_pickle=True)\n",
    "ref_spectra = np.load(\"/data1/xp/data/MSBert/MTBLS1572/ref.npy\", allow_pickle=True)\n",
    "\n",
    "search_with_spectra(\n",
    "    \"MTBLS1572\",\n",
    "    tokenizer,\n",
    "    model,\n",
    "    device,\n",
    "    query_spectra,\n",
    "    ref_spectra,\n",
    "    k_metric,\n",
    "    512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-th answer is [Butyryl-L-carnitine] but get 11-th [Isovaleryl-L-carnitine]\n",
      "18-th answer is [Proline] but get 12-th [Leucine]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(device)\n",
    "\n",
    "batch_size = None\n",
    "k_metric = [5, 1, 10]\n",
    "loader_batch_size = 512\n",
    "show_progress_bar = False\n",
    "\n",
    "replica_suffix = \"-replication-{}\"\n",
    "\n",
    "tokenizer_config = TokenizerConfig(\n",
    "    max_len=100,\n",
    "    n_decimals=2,\n",
    "    show_progress_bar=show_progress_bar\n",
    ")\n",
    "tokenizer = Tokenizer(**tokenizer_config)\n",
    "\n",
    "query_spectra = np.load(\"/data1/xp/data/MSBert/MTBLS1572/query.npy\", allow_pickle=True)\n",
    "ref_spectra = np.load(\"/data1/xp/data/MSBert/MTBLS1572/ref.npy\", allow_pickle=True)\n",
    "\n",
    "query_embedding, _ = embedding(model, device, tokenizer, 512, query_spectra, show_progress_bar)\n",
    "ref_embedding, _ = embedding(model, device, tokenizer, 512, ref_spectra, show_progress_bar)\n",
    "\n",
    "cosine_score = cosine_similarity(\n",
    "    query_embedding, ref_embedding\n",
    ")\n",
    "\n",
    "for i, j in enumerate(np.argmax(cosine_score, axis=1)):\n",
    "    if i != j:\n",
    "        print(f\"{i}-th answer is [{ref_spectra[i].get(\"compound_name\")}] but get {j}-th [{ref_spectra[j].get(\"compound_name\")}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4265302738145448, 0.4380454200931992)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_score[4][4], cosine_score[4][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3376/3376 [00:01<00:00, 3193.80it/s]\n",
      "100%|██████████| 7/7 [00:01<00:00,  6.84it/s]\n",
      "100%|██████████| 15655/15655 [00:04<00:00, 3625.97it/s]\n",
      "100%|██████████| 31/31 [00:02<00:00, 11.12it/s]\n",
      "100%|██████████| 7243/7243 [00:03<00:00, 1928.92it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 11.83it/s]\n",
      "100%|██████████| 674/674 [00:00<00:00, 3504.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 16.53it/s]\n"
     ]
    }
   ],
   "source": [
    "show_progress_bar = True\n",
    "tokenizer = Tokenizer(2, 100, show_progress_bar)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(device)\n",
    "\n",
    "orbitrap_ref_spectra = np.load(mona.ORBITRAP_COMMON, allow_pickle=True)\n",
    "orbitrap_query_spectra = np.load(mona.ORBITRAP_UNIQUE, allow_pickle=True)\n",
    "\n",
    "qtof_ref_spectra = np.load(mona.QTOF_COMMON, allow_pickle=True)\n",
    "qtof_query_spectra = np.load(mona.QTOF_UNIQUE, allow_pickle=True)\n",
    "\n",
    "orbitrap_ref_embedding, _ = embedding(model, device, tokenizer, 512, orbitrap_ref_spectra, show_progress_bar)\n",
    "orbitrap_query_embedding, _ = embedding(model, device, tokenizer, 512, orbitrap_query_spectra,  show_progress_bar)\n",
    "\n",
    "qtof_ref_embedding, _ = embedding(model, device, tokenizer, 512, qtof_ref_spectra, show_progress_bar)\n",
    "qtof_query_embedding, _ = embedding(model, device, tokenizer, 512, qtof_query_spectra,  show_progress_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 31/31 [00:05<00:00,  5.82it/s]\n",
      "processing: 100%|██████████| 2/2 [00:00<00:00, 13.47it/s]\n"
     ]
    }
   ],
   "source": [
    "orbitrap_score, orbitrap_indices = most_similar(orbitrap_query_embedding, orbitrap_ref_embedding, 512, show_progress_bar)\n",
    "qtof_score, qtof_indices = most_similar(qtof_query_embedding, qtof_ref_embedding, 512, show_progress_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = Path(\"/data1/xp/code/specEmbedding/score_distribution/compound search/\")\n",
    "orbitrap_dir = dir / \"orbitrap\"\n",
    "qtof_dir = dir / \"qtof\"\n",
    "\n",
    "orbitrap_dir.mkdir(exist_ok=True, parents=True)\n",
    "qtof_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "np.save(orbitrap_dir / \"MSBERT_Score.npy\", orbitrap_score)\n",
    "np.save(orbitrap_dir / \"MSBERT_Indices.npy\", orbitrap_indices)\n",
    "np.save(qtof_dir / \"MSBERT_Score.npy\", qtof_score)\n",
    "np.save(qtof_dir / \"MSBERT_Indices.npy\", qtof_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(device)\n",
    "\n",
    "batch_size = None\n",
    "k_metric = [5, 1, 10]\n",
    "loader_batch_size = 512\n",
    "show_progress_bar = True\n",
    "\n",
    "tokenizer_config = TokenizerConfig(\n",
    "    max_len=100,\n",
    "    n_decimals=2,\n",
    "    show_progress_bar=show_progress_bar\n",
    ")\n",
    "tokenizer = Tokenizer(**tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3376/3376 [00:01<00:00, 2380.91it/s]\n",
      "100%|██████████| 163952/163952 [00:59<00:00, 2760.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate hit and recall count: 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top5</th>\n",
       "      <th>top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Orbitrap Common</th>\n",
       "      <td>0.80154</td>\n",
       "      <td>0.856043</td>\n",
       "      <td>0.885664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    top1      top5     top10\n",
       "Orbitrap Common  0.80154  0.856043  0.885664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_spectra = np.load(mona.ORBITRAP_COMMON, allow_pickle=True)\n",
    "ref_spectra = np.load(gnps.ORBITRAP_ALL, allow_pickle=True)\n",
    "\n",
    "search_with_spectra(\n",
    "    \"Orbitrap Common\",\n",
    "    tokenizer,\n",
    "    model,\n",
    "    device,\n",
    "    query_spectra,\n",
    "    ref_spectra,\n",
    "    k_metric,\n",
    "    512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize the query and reference data success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculate hit and recall count: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1</th>\n",
       "      <th>top5</th>\n",
       "      <th>top10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QTOF Common</th>\n",
       "      <td>0.984261</td>\n",
       "      <td>0.996134</td>\n",
       "      <td>0.996686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 top1      top5     top10\n",
       "QTOF Common  0.984261  0.996134  0.996686"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_spectra = np.load(mona.QTOF_COMMON, allow_pickle=True)\n",
    "ref_spectra = np.load(gnps.QTOF_ALL, allow_pickle=True)\n",
    "\n",
    "search_with_spectra(\n",
    "    \"QTOF Common\",\n",
    "    tokenizer,\n",
    "    model,\n",
    "    device,\n",
    "    query_spectra,\n",
    "    ref_spectra,\n",
    "    k_metric,\n",
    "    512\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
